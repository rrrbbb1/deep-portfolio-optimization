{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681671b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e50b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAME</th>\n",
       "      <th>AAON</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABCB</th>\n",
       "      <th>ABEO</th>\n",
       "      <th>ABEV</th>\n",
       "      <th>...</th>\n",
       "      <th>YHGJ</th>\n",
       "      <th>YORW</th>\n",
       "      <th>YPF</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZD</th>\n",
       "      <th>ZEUS</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>-0.026382</td>\n",
       "      <td>-0.018070</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>-0.006659</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>-0.025018</td>\n",
       "      <td>-0.017552</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098361</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.013242</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>-0.034330</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>-0.013652</td>\n",
       "      <td>-0.005650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>-0.000430</td>\n",
       "      <td>-0.005915</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>-0.003355</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>-0.003177</td>\n",
       "      <td>-0.031265</td>\n",
       "      <td>-0.043103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115151</td>\n",
       "      <td>-0.044791</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.034882</td>\n",
       "      <td>-0.038308</td>\n",
       "      <td>-0.011431</td>\n",
       "      <td>-0.003611</td>\n",
       "      <td>-0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>-0.021945</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>-0.025806</td>\n",
       "      <td>-0.014815</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>-0.011591</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>0.011282</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>-0.018802</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>-0.000880</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.062914</td>\n",
       "      <td>-0.012987</td>\n",
       "      <td>-0.005774</td>\n",
       "      <td>0.072811</td>\n",
       "      <td>-0.007853</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>-0.024024</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158878</td>\n",
       "      <td>-0.014392</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>-0.012017</td>\n",
       "      <td>-0.003990</td>\n",
       "      <td>-0.024321</td>\n",
       "      <td>0.003802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-10</th>\n",
       "      <td>-0.004844</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>-0.004187</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149194</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-05</th>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.086664</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.028918</td>\n",
       "      <td>-0.003600</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.024061</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006938</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>-0.005590</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.017890</td>\n",
       "      <td>-0.009464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-06</th>\n",
       "      <td>0.032673</td>\n",
       "      <td>0.034505</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.067355</td>\n",
       "      <td>-0.018334</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>-0.011494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.054700</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.022666</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-07</th>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.012901</td>\n",
       "      <td>-0.003344</td>\n",
       "      <td>-0.049712</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>0.008793</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.046816</td>\n",
       "      <td>-0.006076</td>\n",
       "      <td>-0.021953</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>-0.013419</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>-0.013287</td>\n",
       "      <td>-0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-08</th>\n",
       "      <td>-0.013869</td>\n",
       "      <td>-0.026299</td>\n",
       "      <td>-0.010067</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>-0.004955</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>-0.024904</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084469</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.031098</td>\n",
       "      <td>0.034891</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.006380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-09</th>\n",
       "      <td>0.018935</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.027119</td>\n",
       "      <td>0.043979</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>0.033714</td>\n",
       "      <td>0.027784</td>\n",
       "      <td>-0.009701</td>\n",
       "      <td>0.003170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5288 rows × 2135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             A        AA      AAME      AAON       AAP      AAPL  \\\n",
       "Date                                                                     \n",
       "2005-01-04 -0.026382 -0.018070  0.026059 -0.007329 -0.006659  0.010270   \n",
       "2005-01-05 -0.000430 -0.005915 -0.015873 -0.003355  0.001849  0.008758   \n",
       "2005-01-06 -0.021945  0.004298 -0.025806 -0.014815 -0.000923  0.000775   \n",
       "2005-01-07 -0.000880  0.010204  0.062914 -0.012987 -0.005774  0.072811   \n",
       "2005-01-10 -0.004844 -0.007168  0.018692 -0.002078  0.003484 -0.004187   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2026-01-05  0.036100  0.086664  0.031250  0.028918 -0.003600 -0.013837   \n",
       "2026-01-06  0.032673  0.034505  0.006734  0.002332  0.067355 -0.018334   \n",
       "2026-01-07  0.001423 -0.012901 -0.003344 -0.049712 -0.003385 -0.007737   \n",
       "2026-01-08 -0.013869 -0.026299 -0.010067  0.028347  0.028142 -0.004955   \n",
       "2026-01-09  0.018935  0.042233  0.027119  0.043979  0.034450  0.001274   \n",
       "\n",
       "Ticker            AB      ABCB      ABEO      ABEV  ...      YHGJ      YORW  \\\n",
       "Date                                                ...                       \n",
       "2005-01-04 -0.025018 -0.017552  0.011628  0.000000  ... -0.098361 -0.006500   \n",
       "2005-01-05 -0.003177 -0.031265 -0.043103  0.000000  ...  0.115151 -0.044791   \n",
       "2005-01-06 -0.000981  0.021004  0.000000 -0.020000  ...  0.163043 -0.011591   \n",
       "2005-01-07 -0.007853 -0.014049 -0.024024  0.002721  ...  0.158878 -0.014392   \n",
       "2005-01-10  0.002473  0.018829  0.012308  0.000000  ...  0.149194  0.001082   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2026-01-05  0.016822  0.024061 -0.016949  0.016194  ...  0.000000 -0.006938   \n",
       "2026-01-06  0.007636  0.005808 -0.011494  0.000000  ...  0.011142  0.005081   \n",
       "2026-01-07 -0.015913  0.008793  0.011628  0.000000  ...  0.011019 -0.002844   \n",
       "2026-01-08 -0.014374  0.027579 -0.024904 -0.003984  ...  0.084469  0.016477   \n",
       "2026-01-09 -0.002344  0.001772  0.019646  0.024000  ...  0.010050  0.000935   \n",
       "\n",
       "Ticker           YPF       YUM       ZBH      ZBRA        ZD      ZEUS  \\\n",
       "Date                                                                     \n",
       "2005-01-04 -0.003460 -0.013242 -0.000378 -0.018735 -0.034330  0.005948   \n",
       "2005-01-05  0.001852 -0.002381 -0.007814 -0.034882 -0.038308 -0.011431   \n",
       "2005-01-06  0.007625  0.011282  0.011559  0.001522 -0.018802 -0.000797   \n",
       "2005-01-07 -0.000229 -0.005578 -0.001758  0.008547 -0.012017 -0.003990   \n",
       "2005-01-10 -0.000459  0.000216  0.009560  0.013936  0.009533  0.016426   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2026-01-05  0.002480 -0.001329  0.029216  0.017479 -0.005590  0.010030   \n",
       "2026-01-06 -0.054700  0.007452  0.022666  0.019672  0.014201  0.011736   \n",
       "2026-01-07 -0.046816 -0.006076 -0.021953 -0.041341 -0.013419  0.005130   \n",
       "2026-01-08  0.031117  0.019868  0.015215  0.031098  0.034891  0.038393   \n",
       "2026-01-09  0.008284  0.013292 -0.013074  0.019007  0.033714  0.027784   \n",
       "\n",
       "Ticker          ZION       ZTR  \n",
       "Date                            \n",
       "2005-01-04 -0.013652 -0.005650  \n",
       "2005-01-05 -0.003611 -0.003788  \n",
       "2005-01-06  0.005738  0.000000  \n",
       "2005-01-07 -0.024321  0.003802  \n",
       "2005-01-10  0.000615 -0.003788  \n",
       "...              ...       ...  \n",
       "2026-01-05  0.017890 -0.009464  \n",
       "2026-01-06  0.010778  0.004777  \n",
       "2026-01-07 -0.013287 -0.006339  \n",
       "2026-01-08  0.011139  0.006380  \n",
       "2026-01-09 -0.009701  0.003170  \n",
       "\n",
       "[5288 rows x 2135 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df = pd.read_parquet('/Users/remibreton/Documents/data/stocks_data.parquet')\n",
    "\n",
    "tickers = stocks_df.groupby('Ticker')['Close'].count().sort_values(ascending=False)\n",
    "tickers = tickers[tickers == max(tickers)].index.to_list()\n",
    "stocks_df = stocks_df[stocks_df['Ticker'].isin(tickers)]\n",
    "close_df = stocks_df.pivot(index='Date', columns='Ticker', values='Close')\n",
    "\n",
    "returns_df = close_df.pct_change()[1:]\n",
    "returns_df = returns_df.fillna(0)\n",
    "returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f873f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PortfolioDataset(Dataset):\n",
    "    def __init__(self, returns_df: pd.DataFrame, lookback: int = 60, decision_step: int = 10, n_asset: int = 10, n_samples: int = 100_000):\n",
    "        self.returns = returns_df.values.astype(np.float32)\n",
    "        self.T, self.N = self.returns.shape\n",
    "\n",
    "        self.lookback = lookback\n",
    "        self.decision_step = decision_step\n",
    "        self.window_length = lookback + decision_step\n",
    "\n",
    "        self.k = n_asset\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        t = np.random.randint(self.window_length, self.T)\n",
    "        asset_idx = np.random.choice(self.N, self.k, replace=False)\n",
    "        window = self.returns[t - self.lookback:t, asset_idx]\n",
    "        \n",
    "        return {'input_r': torch.tensor(window), 'asset_idx': torch.tensor(asset_idx)}\n",
    "\n",
    "num_timesteps, _ = returns_df.shape\n",
    "train_lim = int(0.8 * num_timesteps)\n",
    "\n",
    "train_df = returns_df[:train_lim]\n",
    "test_df = returns_df[train_lim:]\n",
    "\n",
    "train_dataset = PortfolioDataset(train_df)\n",
    "test_dataset = PortfolioDataset(test_df)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa207f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class POptModel(torch.nn.Module):\n",
    "    def __init__(self, n_asset: int, decision_step: int = 20, hidden_dim: int = 64, num_layers: int = 5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_asset = n_asset\n",
    "        self.decision_step = decision_step\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = n_asset,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        self.head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, n_asset)\n",
    "        )\n",
    "    \n",
    "    def forward(self, r):\n",
    "        h_t, _ = self.lstm(r)\n",
    "        #print('h_t.shape: ', h_t.shape)\n",
    "\n",
    "        h_decision = h_t[: , self.decision_step:-1, :]\n",
    "        #print('h_decision.shape: ', h_decision.shape)\n",
    "\n",
    "        scores = self.head(h_decision)\n",
    "        #print('scores.shape: ', scores.shape)\n",
    "\n",
    "        w = F.softmax(scores, dim=-1)\n",
    "        #print('w.shape: ', w.shape)\n",
    "\n",
    "        next_r = r[:, self.decision_step+1:, :]\n",
    "        #print('next_r.shape: ', next_r.shape)\n",
    "        \n",
    "        return w, next_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharpeLoss(torch.nn.Module):\n",
    "    def __init__(self, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, w, next_r):\n",
    "        \n",
    "        port_returns = torch.sum(w * next_r, dim=-1)\n",
    "        #print('port_returns.shape: ', port_returns.shape)\n",
    "\n",
    "        mean_t = port_returns.mean(dim=1) \n",
    "        var_t = port_returns.var(dim=1, unbiased=False)\n",
    "        sharpe_t = mean_t / torch.sqrt(var_t + self.eps)\n",
    "\n",
    "        return -sharpe_t.mean()\n",
    "\n",
    "class WeightPenalty(torch.nn.Module):\n",
    "    def __init__(self, param: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.param = param\n",
    "    \n",
    "    def forward(self, w):\n",
    "        delta_w = w[:, 1:, :] - w[:, :-1, :]\n",
    "        penalty_k = torch.sum(torch.abs(delta_w), dim=1)\n",
    "        penalty = torch.sum(penalty_k, dim=1)\n",
    "\n",
    "        return self.param * penalty.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018310ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "Running epoch 001 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:12<00:00, 30.70it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 35.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss       : -0.0585 | Test Loss: -0.0236 | \n",
      "          | Train Sharpe.    : 0.0585  | Test Sharpe: 0.0236 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 002 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:12<00:00, 30.66it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:09<00:00, 39.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Train Loss       : -0.0592 | Test Loss: -0.0240 | \n",
      "          | Train Sharpe.    : 0.0592  | Test Sharpe: 0.0240 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 003 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 29.24it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Train Loss       : -0.0582 | Test Loss: -0.0231 | \n",
      "          | Train Sharpe.    : 0.0582  | Test Sharpe: 0.0231 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 004 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:12<00:00, 30.70it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Train Loss       : -0.0589 | Test Loss: -0.0239 | \n",
      "          | Train Sharpe.    : 0.0589  | Test Sharpe: 0.0239 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 005 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 29.78it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 37.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Train Loss       : -0.0579 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0579  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 006 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:14<00:00, 27.49it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 37.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Train Loss       : -0.0591 | Test Loss: -0.0234 | \n",
      "          | Train Sharpe.    : 0.0591  | Test Sharpe: 0.0234 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 007 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 28.93it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Train Loss       : -0.0595 | Test Loss: -0.0228 | \n",
      "          | Train Sharpe.    : 0.0595  | Test Sharpe: 0.0228 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 008 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:17<00:00, 22.86it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Train Loss       : -0.0593 | Test Loss: -0.0243 | \n",
      "          | Train Sharpe.    : 0.0593  | Test Sharpe: 0.0243 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 009 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 25.29it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Train Loss       : -0.0590 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0590  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 010 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 29.65it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Train Loss       : -0.0574 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0574  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 011 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 28.50it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:11<00:00, 34.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Train Loss       : -0.0585 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0585  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 012 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 28.44it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:09<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Train Loss       : -0.0590 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0590  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 013 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:12<00:00, 30.84it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:09<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Train Loss       : -0.0592 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0592  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 014 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:12<00:00, 31.01it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:09<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Train Loss       : -0.0590 | Test Loss: -0.0234 | \n",
      "          | Train Sharpe.    : 0.0590  | Test Sharpe: 0.0234 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 015 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:13<00:00, 30.04it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:09<00:00, 41.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Train Loss       : -0.0579 | Test Loss: -0.0234 | \n",
      "          | Train Sharpe.    : 0.0579  | Test Sharpe: 0.0234 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 016 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:18<00:00, 21.59it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:09<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Train Loss       : -0.0587 | Test Loss: -0.0245 | \n",
      "          | Train Sharpe.    : 0.0587  | Test Sharpe: 0.0245 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 017 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 25.17it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Train Loss       : -0.0591 | Test Loss: -0.0228 | \n",
      "          | Train Sharpe.    : 0.0591  | Test Sharpe: 0.0228 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 018 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 24.88it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Train Loss       : -0.0589 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0589  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 019 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 25.26it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Train Loss       : -0.0587 | Test Loss: -0.0236 | \n",
      "          | Train Sharpe.    : 0.0587  | Test Sharpe: 0.0236 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 020 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 25.09it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 37.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Train Loss       : -0.0593 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0593  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 021 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:14<00:00, 26.89it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Train Loss       : -0.0581 | Test Loss: -0.0225 | \n",
      "          | Train Sharpe.    : 0.0581  | Test Sharpe: 0.0225 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 022 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 25.29it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Train Loss       : -0.0596 | Test Loss: -0.0235 | \n",
      "          | Train Sharpe.    : 0.0596  | Test Sharpe: 0.0235 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 023 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 24.75it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Train Loss       : -0.0584 | Test Loss: -0.0233 | \n",
      "          | Train Sharpe.    : 0.0584  | Test Sharpe: 0.0233 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 024 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 24.83it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 38.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Train Loss       : -0.0589 | Test Loss: -0.0237 | \n",
      "          | Train Sharpe.    : 0.0589  | Test Sharpe: 0.0237 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 025 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 25.32it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 37.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Train Loss       : -0.0585 | Test Loss: -0.0233 | \n",
      "          | Train Sharpe.    : 0.0585  | Test Sharpe: 0.0233 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 026 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:14<00:00, 27.31it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 36.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Train Loss       : -0.0595 | Test Loss: -0.0234 | \n",
      "          | Train Sharpe.    : 0.0595  | Test Sharpe: 0.0234 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 027 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:15<00:00, 24.66it/s]\n",
      "Eval: 100%|██████████| 391/391 [00:10<00:00, 37.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Train Loss       : -0.0593 | Test Loss: -0.0232 | \n",
      "          | Train Sharpe.    : 0.0593  | Test Sharpe: 0.0232 | \n",
      "          | Train Weight Pen.: 0.0000  | Test Weight Pen.: 0.0000 | \n",
      "\n",
      "Running epoch 028 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 391/391 [00:14<00:00, 27.19it/s]\n",
      "Eval:  67%|██████▋   | 261/391 [00:07<00:03, 34.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m weight_loss \u001b[38;5;241m=\u001b[39m weight_crit(w)\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m sharpe_loss \u001b[38;5;241m+\u001b[39m weight_loss\n\u001b[0;32m---> 64\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m test_sharpe_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sharpe_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     66\u001b[0m test_weight_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weight_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f'using device: {device}')\n",
    "\n",
    "model = POptModel(n_asset = train_dataset.k).to(device)\n",
    "\n",
    "sharpe_crit = SharpeLoss().to(device)\n",
    "weight_crit = WeightPenalty().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "n_epoch = 100\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_sharpe_loss = 0.0\n",
    "    train_weight_loss = 0.0\n",
    "\n",
    "    print(\n",
    "        f\"Running epoch {epoch+1:03d} ...\"\n",
    "    )\n",
    "    \n",
    "    for batch in tqdm(train_dataloader, desc=\"Train\"):\n",
    "        x = batch['input_r'].to(device)      # (B, L, K)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        w, next_r = model(x)\n",
    "        sharpe_loss = sharpe_crit(w, next_r)\n",
    "        weight_loss = weight_crit(w)\n",
    "        loss = sharpe_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_sharpe_loss += sharpe_loss.item()\n",
    "        train_weight_loss += weight_loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_sharpe_loss /= len(train_dataloader)\n",
    "    train_weight_loss /= len(train_dataloader)\n",
    "\n",
    "    # --------------------\n",
    "    # Evaluation\n",
    "    # --------------------\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_sharpe_loss = 0.0\n",
    "    test_weight_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Eval\"):\n",
    "            x = batch['input_r'].to(device)\n",
    "\n",
    "            w, next_r = model(x)\n",
    "            sharpe_loss = sharpe_crit(w, next_r)\n",
    "            weight_loss = weight_crit(w)\n",
    "            loss = sharpe_loss + weight_loss\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_sharpe_loss += sharpe_loss.item()\n",
    "            test_weight_loss += weight_loss.item()\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_sharpe_loss /= len(test_dataloader)\n",
    "    test_weight_loss /= len(test_dataloader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:03d} | \"\n",
    "        f\"Train Loss       : {train_loss:.4f} | \"\n",
    "        f\"Test Loss: {test_loss:.4f}               | \\n\"\n",
    "\n",
    "        f\"          | \"\n",
    "        f\"Train Sharpe.    : {-train_sharpe_loss:.4f}  | \"\n",
    "        f\"Test Sharpe: {-test_sharpe_loss:.4f}     | \\n\"\n",
    "\n",
    "        f\"          | \"\n",
    "        f\"Train Weight Pen.: {train_weight_loss:.4f}  | \"\n",
    "        f\"Test Weight Pen.: {test_weight_loss:.4f} | \\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
